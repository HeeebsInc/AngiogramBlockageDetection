{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from img_utils import automatic_brightness_and_contrast, find_if_close\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you are to apply image segmentation techniques to X-ray angiography, where X-ray images are taken when an X-ray absorbing substance is injected into the patient's blood stream to produce contrast. The resulting X-ray images have dark regions representing the blood flow within vessels. Your system should be able to automatically locate any occlusion and follow the surrounding vessel wall to compute the ratio between the minimum and nominal vessel diameters. Such results are practically important in detecting coronary disease. Your system should also accept user input of occlusion locations and perform the same percent occlusion measurement in that particular area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '../sample-images'\n",
    "image_names = os.listdir(images_dir)\n",
    "# image_name = shuffle(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "fig, ax = plt.subplots(2, 1, figsize = (20,10))\n",
    "\n",
    "for idx, image_name in enumerate(image_names):\n",
    "    \n",
    "    full_path = f'{images_dir}/{image_name}' \n",
    "    img = cv2.imread(full_path)\n",
    "    x_new = int(img.shape[1] * .1)\n",
    "    y_new = int(img.shape[0] * .1)\n",
    "    img = img[y_new:img.shape[0] - y_new, x_new: img.shape[1] - x_new]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = automatic_brightness_and_contrast(gray)\n",
    "#     blurred = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "    blurred = cv2.medianBlur(gray, 3)\n",
    "#     blurred = automatic_brightness_and_contrast(blurred)\n",
    "    block_size = int(img.shape[0] / 12 )\n",
    "    block_size = block_size + 1 if block_size % 2 == 0 else block_size\n",
    "    \n",
    "    edged_adap = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, block_size, 10)\n",
    "#     edged_adap = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU, block_size)[0]\n",
    "\n",
    "    min_contour_area = 1000\n",
    "    \n",
    "    thresh = cv2.morphologyEx(edged_adap, cv2.MORPH_ELLIPSE, np.ones((3,3), np.uint8))\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    contours =[i for i in contours if cv2.contourArea(i) > min_contour_area]\n",
    "    edged_contour = img.copy()\n",
    "    new_contours = []\n",
    "    for idx1, c1 in enumerate(contours):\n",
    "        cv2.drawContours(edged_contour, [c1], -1, (0,0,0), -1)\n",
    "        if idx1 == len(contours) - 1:\n",
    "            break\n",
    "#         for idx2, c2 in enumerate(contours):\n",
    "#             dist = find_if_close(c1, c2, 5)\n",
    "#             if dist:\n",
    "#                 hulled = cv2.convexHull(np.vstack([c1, c2]))\n",
    "#                 new_contours.append(hulled)\n",
    "                \n",
    "#     contour_test = img.copy()\n",
    "#     cv2.drawContours(contour_test, new_contours, -1, (255,0,0), -1)\n",
    "#     contour_test = cv2.cvtColor(contour_test, cv2.COLOR_BGR2GRAY)\n",
    "#     contour_test = cv2.threshold(contour_test, 0, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "    edged_contour = cv2.cvtColor(edged_contour, cv2.COLOR_BGR2GRAY)\n",
    "    threshed = cv2.threshold(edged_contour, 0, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "#     edged_adap_2 = cv2.adaptiveThreshold(edged_contour, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, block_size, 10)\n",
    "#     edge_mask = cv2.threshold(edged_contour, 254, 255, cv2.THRESH_BINARY_INV)[0]\n",
    "    dilated = cv2.dilate(threshed, None, iterations = 15)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (7,7))\n",
    "    closing = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    mask = cv2.bitwise_xor(threshed.copy(), dilated)\n",
    "#     mask = cv2.bitwise_not(blurred.copy(), blurred.copy(), threshed)\n",
    "    stacked = np.hstack([blurred, edged_adap, edged_contour, threshed, dilated, mask])\n",
    "    ax[idx].imshow(stacked, cmap = 'gray')\n",
    "    ax[idx].set_title(image_name)\n",
    "    \n",
    "#     ax[1].imshow(contour_test)\n",
    "#     break\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Block Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "for image_name in image_names:\n",
    "    \n",
    "    full_path = f'{images_dir}/{image_name}' \n",
    "    img = cv2.imread(full_path)\n",
    "    x_new = int(img.shape[1] * .1)\n",
    "    y_new = int(img.shape[0] * .1)\n",
    "    img = img[y_new:img.shape[0] - y_new, x_new: img.shape[1] - x_new]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     gray = automatic_brightness_and_contrast(gray)\n",
    "#     blurred = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    blurred = cv2.medianBlur(gray, 15)\n",
    "#     blurred = cv2.blur(gray, (9,9))\n",
    "#     blurred = cv2.bilateralFilter(gray, 15, 350, 350)\n",
    "    blurred = automatic_brightness_and_contrast(blurred)\n",
    "    stacked = []\n",
    "    blocks = list(range(6, 23, 2))\n",
    "    block_values = []\n",
    "    for i in blocks:\n",
    "        block_size = int(img.shape[0] / i)\n",
    "        block_size = block_size + 1 if block_size % 2 == 0 else block_size\n",
    "        block_values.append(block_size)\n",
    "        edged = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, block_size, 10)\n",
    "        stacked.append(edged)\n",
    "    fig, ax = plt.subplots(1, len(blocks) + 1, figsize = (10,10))\n",
    "    ax[0].imshow(blurred, cmap = 'gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    for idx, (edge_img, block, block_value) in enumerate(zip(stacked, blocks, block_values)):\n",
    "        idx += 1\n",
    "        ax[idx].imshow(edge_img, cmap = 'gray')\n",
    "        ax[idx].set_title(f'Block Size {block_value} ({block})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "        \n",
    "#     stacked = np.hstack(stacked)\n",
    "#     plt.imshow(stacked, cmap = 'gray')\n",
    "#     plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dash-Dab-Tlt",
   "language": "python",
   "name": "dash-dab-tlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
